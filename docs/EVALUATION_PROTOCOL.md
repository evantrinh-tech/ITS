#  PROTOCOL ƒê√ÅNH GI√Å H·ªÜ TH·ªêNG PH√ÅT HI·ªÜN S·ª∞ C·ªê GIAO TH√îNG

## üìã M·ª§C L·ª§C

1. [Chia d·ªØ li·ªáu Train/Val/Test](#1-chia-d·ªØ-li·ªáu-trainvaltest)
2. [Ch·ªçn Threshold tr√™n Validation](#2-ch·ªçn-threshold-tr√™n-validation)
3. [ƒê·ªãnh nghƒ©a v√† T√≠nh MTTD](#3-ƒë·ªãnh-nghƒ©a-v√†-t√≠nh-mttd)
4. [Bi·ªÉu ƒë·ªì B·∫Øt bu·ªôc](#4-bi·ªÉu-ƒë·ªì-b·∫Øt-bu·ªôc)
5. [Checklist Ki·ªÉm tra Sai l·∫ßm](#5-checklist-ki·ªÉm-tra-sai-l·∫ßm)

---

## 1. CHIA D·ªÆ LI·ªÜU TRAIN/VAL/TEST

### 1.1. Nguy√™n t·∫Øc Chia d·ªØ li·ªáu

**QUAN TR·ªåNG**: Ph·∫£i tr√°nh data leakage theo 3 chi·ªÅu:
- **Incident-level**: C√°c frames c·ªßa c√πng m·ªôt incident ph·∫£i c√πng m·ªôt split
- **Camera-level**: D·ªØ li·ªáu t·ª´ c√πng m·ªôt camera n√™n c√πng m·ªôt split
- **Time-level**: D·ªØ li·ªáu theo th·ªùi gian ph·∫£i ƒë∆∞·ª£c chia tu·∫ßn t·ª± (kh√¥ng random)

### 1.2. Ph∆∞∆°ng ph√°p Chia cho Image Data

```python
def split_image_data_by_incident(
    data_path: Path,
    train_ratio: float = 0.7,
    val_ratio: float = 0.15,
    test_ratio: float = 0.15
) -> Tuple[List[Path], List[Path], List[Path]]:
    """
    Chia d·ªØ li·ªáu ·∫£nh theo incident ƒë·ªÉ tr√°nh leakage
    
    Strategy:
    1. Group ·∫£nh theo incident (n·∫øu c√≥ metadata)
    2. Ho·∫∑c group theo th∆∞ m·ª•c con (n·∫øu m·ªói th∆∞ m·ª•c l√† m·ªôt incident)
    3. Chia incidents th√†nh train/val/test
    4. T·∫•t c·∫£ ·∫£nh c·ªßa m·ªôt incident c√πng m·ªôt split
    """
    # Load t·∫•t c·∫£ ·∫£nh
    normal_images = list((data_path / "normal").glob("*.jpg"))
    incident_images = list((data_path / "incident").glob("*.jpg"))
    
    # Group theo incident (gi·∫£ s·ª≠ c√≥ metadata ho·∫∑c naming convention)
    # V√≠ d·ª•: incident_001_frame_001.jpg, incident_001_frame_002.jpg
    incident_groups = {}
    for img in incident_images:
        # Extract incident ID t·ª´ t√™n file
        incident_id = extract_incident_id(img.name)  # C·∫ßn implement
        if incident_id not in incident_groups:
            incident_groups[incident_id] = []
        incident_groups[incident_id].append(img)
    
    # Chia incidents (kh√¥ng ph·∫£i ·∫£nh)
    incident_ids = list(incident_groups.keys())
    np.random.seed(42)
    np.random.shuffle(incident_ids)
    
    n_total = len(incident_ids)
    n_train = int(n_total * train_ratio)
    n_val = int(n_total * val_ratio)
    
    train_incidents = incident_ids[:n_train]
    val_incidents = incident_ids[n_train:n_train+n_val]
    test_incidents = incident_ids[n_train+n_val:]
    
    # Collect images theo split
    train_images = []
    val_images = []
    test_images = []
    
    for incident_id in train_incidents:
        train_images.extend(incident_groups[incident_id])
    for incident_id in val_incidents:
        val_images.extend(incident_groups[incident_id])
    for incident_id in test_incidents:
        test_images.extend(incident_groups[incident_id])
    
    # Normal images: chia random (kh√¥ng c√≥ incident grouping)
    np.random.shuffle(normal_images)
    n_normal = len(normal_images)
    train_normal = normal_images[:int(n_normal * train_ratio)]
    val_normal = normal_images[int(n_normal * train_ratio):int(n_normal * (train_ratio + val_ratio))]
    test_normal = normal_images[int(n_normal * (train_ratio + val_ratio)):]
    
    train_images.extend(train_normal)
    val_images.extend(val_normal)
    test_images.extend(test_normal)
    
    return train_images, val_images, test_images
```

### 1.3. Ph∆∞∆°ng ph√°p Chia cho Video Data

```python
def split_video_data_by_time(
    video_list: List[Path],
    train_ratio: float = 0.7,
    val_ratio: float = 0.15,
    test_ratio: float = 0.15
) -> Tuple[List[Path], List[Path], List[Path]]:
    """
    Chia video theo th·ªùi gian (time-based split)
    
    Strategy:
    1. Sort videos theo timestamp
    2. Chia tu·∫ßn t·ª±: train (70%) ‚Üí val (15%) ‚Üí test (15%)
    3. Kh√¥ng random ƒë·ªÉ tr√°nh future leakage
    """
    # Sort theo timestamp (t·ª´ metadata ho·∫∑c filename)
    sorted_videos = sort_videos_by_time(video_list)
    
    n_total = len(sorted_videos)
    n_train = int(n_total * train_ratio)
    n_val = int(n_total * val_ratio)
    
    train_videos = sorted_videos[:n_train]
    val_videos = sorted_videos[n_train:n_train+n_val]
    test_videos = sorted_videos[n_train+n_val:]
    
    return train_videos, val_videos, test_videos
```

### 1.4. Validation Checklist

- [ ] Kh√¥ng c√≥ incident n√†o xu·∫•t hi·ªán ·ªü c·∫£ train v√† test
- [ ] Kh√¥ng c√≥ camera n√†o xu·∫•t hi·ªán ·ªü c·∫£ train v√† test (n·∫øu c√≥ metadata camera)
- [ ] Test set ƒë∆∞·ª£c l·∫•y t·ª´ th·ªùi gian sau train/val (time-based split)
- [ ] T·ªâ l·ªá class (normal/incident) t∆∞∆°ng ƒë∆∞∆°ng gi·ªØa train/val/test
- [ ] K√≠ch th∆∞·ªõc test set ‚â• 20% t·ªïng d·ªØ li·ªáu

---

## 2. CH·ªåN THRESHOLD TR√äN VALIDATION

### 2.1. M·ª•c ti√™u V·∫≠n h√†nh

T√πy v√†o use case, ch·ªçn threshold theo m·ª•c ti√™u:

| Use Case | M·ª•c ti√™u | Strategy |
|----------|----------|----------|
| **An to√†n cao** | Recall ‚â• 0.9, FAR ch·∫•p nh·∫≠n ƒë∆∞·ª£c | ∆Øu ti√™n Recall, threshold th·∫•p (0.3-0.4) |
| **Gi·∫£m False Alarm** | FAR ‚â§ 1%, Recall ‚â• 0.85 | C√¢n b·∫±ng, threshold trung b√¨nh (0.5-0.6) |
| **Precision cao** | Precision ‚â• 0.95 | ∆Øu ti√™n Precision, threshold cao (0.7-0.8) |

### 2.2. Ph∆∞∆°ng ph√°p Tune Threshold

```python
def tune_threshold_on_validation(
    y_val_proba: np.ndarray,
    y_val_true: np.ndarray,
    target_recall: float = 0.9,
    target_far: float = 0.01
) -> Dict[str, Any]:
    """
    Tune threshold tr√™n validation set
    
    Args:
        y_val_proba: X√°c su·∫•t t·ª´ model tr√™n validation set
        y_val_true: Nh√£n th·ª±c t·∫ø
        target_recall: M·ª•c ti√™u Recall (default 0.9)
        target_far: M·ª•c ti√™u FAR (default 0.01 = 1%)
        
    Returns:
        Dict ch·ª©a best threshold v√† metrics
    """
    from sklearn.metrics import recall_score, precision_score, confusion_matrix
    
    thresholds = np.arange(0.1, 0.95, 0.01)
    best_threshold = 0.5
    best_metrics = None
    best_score = -1
    
    for threshold in thresholds:
        y_pred = (y_val_proba >= threshold).astype(int)
        
        recall = recall_score(y_val_true, y_pred, zero_division=0)
        precision = precision_score(y_val_true, y_pred, zero_division=0)
        
        cm = confusion_matrix(y_val_true, y_pred)
        if cm.size == 4:
            tn, fp, fn, tp = cm.ravel()
            far = fp / (fp + tn) if (fp + tn) > 0 else 0.0
        else:
            far = 0.0
        
        # Score: ƒë·∫°t c·∫£ 2 m·ª•c ti√™u
        score = 0
        if recall >= target_recall:
            score += 1
        if far <= target_far:
            score += 1
        
        # N·∫øu ƒë·∫°t c·∫£ 2, ∆∞u ti√™n F1 cao
        if score == 2:
            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
            if f1 > best_score:
                best_score = f1
                best_threshold = threshold
                best_metrics = {
                    "threshold": threshold,
                    "recall": recall,
                    "precision": precision,
                    "f1_score": f1,
                    "far": far,
                    "tp": int(tp), "fp": int(fp), "tn": int(tn), "fn": int(fn)
                }
    
    if best_metrics is None:
        # Kh√¥ng t√¨m th·∫•y threshold ƒë·∫°t c·∫£ 2 m·ª•c ti√™u
        # Ch·ªçn threshold c√≥ Recall g·∫ßn target nh·∫•t
        for threshold in thresholds:
            y_pred = (y_val_proba >= threshold).astype(int)
            recall = recall_score(y_val_true, y_pred, zero_division=0)
            if abs(recall - target_recall) < abs(best_metrics.get("recall", 1.0) - target_recall):
                # T√≠nh l·∫°i metrics
                precision = precision_score(y_val_true, y_pred, zero_division=0)
                cm = confusion_matrix(y_val_true, y_pred)
                if cm.size == 4:
                    tn, fp, fn, tp = cm.ravel()
                    far = fp / (fp + tn) if (fp + tn) > 0 else 0.0
                else:
                    far = 0.0
                
                best_threshold = threshold
                best_metrics = {
                    "threshold": threshold,
                    "recall": recall,
                    "precision": precision,
                    "f1_score": 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0,
                    "far": far,
                    "tp": int(tp), "fp": int(fp), "tn": int(tn), "fn": int(fn)
                }
    
    return best_metrics
```

### 2.3. Validation Curve

V·∫Ω bi·ªÉu ƒë·ªì **FAR vs Recall** v√† **Precision vs Recall** ƒë·ªÉ ch·ªçn threshold:

```python
def plot_threshold_curves(
    y_val_proba: np.ndarray,
    y_val_true: np.ndarray,
    save_path: Optional[Path] = None
):
    """
    V·∫Ω bi·ªÉu ƒë·ªì threshold curves
    """
    import matplotlib.pyplot as plt
    
    thresholds = np.arange(0.1, 0.95, 0.01)
    recalls = []
    precisions = []
    fars = []
    
    for threshold in thresholds:
        y_pred = (y_val_proba >= threshold).astype(int)
        recall = recall_score(y_val_true, y_pred, zero_division=0)
        precision = precision_score(y_val_true, y_pred, zero_division=0)
        cm = confusion_matrix(y_val_true, y_pred)
        if cm.size == 4:
            tn, fp, fn, tp = cm.ravel()
            far = fp / (fp + tn) if (fp + tn) > 0 else 0.0
        else:
            far = 0.0
        
        recalls.append(recall)
        precisions.append(precision)
        fars.append(far)
    
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    
    # FAR vs Recall
    axes[0].plot(recalls, fars, 'b-', linewidth=2)
    axes[0].set_xlabel('Recall')
    axes[0].set_ylabel('False Alarm Rate (FAR)')
    axes[0].set_title('FAR vs Recall Curve')
    axes[0].grid(True)
    
    # Precision vs Recall (PR Curve)
    axes[1].plot(recalls, precisions, 'r-', linewidth=2)
    axes[1].set_xlabel('Recall')
    axes[1].set_ylabel('Precision')
    axes[1].set_title('Precision-Recall Curve')
    axes[1].grid(True)
    
    plt.tight_layout()
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()
```

---

## 3. ƒê·ªäNH NGHƒ®A V√Ä T√çNH MTTD

### 3.1. ƒê·ªãnh nghƒ©a MTTD (Mean Time To Detection)

**MTTD** = Th·ªùi gian trung b√¨nh t·ª´ khi s·ª± c·ªë x·∫£y ra ƒë·∫øn khi h·ªá th·ªëng ph√°t hi·ªán ƒë∆∞·ª£c.

**ƒê∆°n v·ªã**: Gi√¢y (seconds)

### 3.2. C√°ch t√≠nh MTTD t·ª´ Frame/Video Data

```python
def calculate_mttd(
    y_true: np.ndarray,
    y_pred: np.ndarray,
    timestamps: Optional[np.ndarray] = None,
    fps: float = 30.0
) -> float:
    """
    T√≠nh Mean Time To Detection (MTTD)
    
    Args:
        y_true: Nh√£n th·ª±c t·∫ø (0/1) theo frame
        y_pred: Predictions (0/1) theo frame
        timestamps: Timestamps th·ª±c t·∫ø (gi√¢y), n·∫øu None s·∫Ω t√≠nh t·ª´ frame_number/fps
        fps: Frames per second
        
    Returns:
        MTTD (gi√¢y)
    """
    if timestamps is None:
        timestamps = np.arange(len(y_true)) / fps
    
    detection_times = []
    
    # T√¨m c√°c incident th·ª±c t·∫ø
    incident_starts = []
    incident_ends = []
    
    in_incident = False
    start_idx = None
    
    for i, label in enumerate(y_true):
        if label == 1 and not in_incident:
            # B·∫Øt ƒë·∫ßu incident
            in_incident = True
            start_idx = i
        elif label == 0 and in_incident:
            # K·∫øt th√∫c incident
            incident_starts.append(start_idx)
            incident_ends.append(i - 1)
            in_incident = False
    
    # N·∫øu incident k√©o d√†i ƒë·∫øn cu·ªëi
    if in_incident:
        incident_starts.append(start_idx)
        incident_ends.append(len(y_true) - 1)
    
    # T√≠nh th·ªùi gian detection cho m·ªói incident
    for start_idx, end_idx in zip(incident_starts, incident_ends):
        incident_start_time = timestamps[start_idx]
        
        # T√¨m frame ƒë·∫ßu ti√™n model ph√°t hi·ªán ƒë∆∞·ª£c (trong window)
        detection_idx = None
        window = int(fps * 10)  # T√¨m trong 10 gi√¢y sau khi incident b·∫Øt ƒë·∫ßu
        
        search_start = start_idx
        search_end = min(start_idx + window, len(y_pred))
        
        for i in range(search_start, search_end):
            if y_pred[i] == 1:
                detection_idx = i
                break
        
        if detection_idx is not None:
            detection_time = timestamps[detection_idx] - incident_start_time
            detection_times.append(detection_time)
        else:
            # Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c (False Negative)
            # C√≥ th·ªÉ b·ªè qua ho·∫∑c t√≠nh l√† MTTD = infinity
            pass
    
    if len(detection_times) == 0:
        return 0.0  # Ho·∫∑c return np.inf n·∫øu mu·ªën b√°o kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c
    
    return np.mean(detection_times)
```

### 3.3. MTTD theo Event

N·∫øu d·ªØ li·ªáu ƒë∆∞·ª£c label theo **event** (kh√¥ng ph·∫£i frame-by-frame):

```python
def calculate_mttd_by_events(
    incident_events: List[Dict],  # [{"start_time": 10.5, "end_time": 15.2}, ...]
    detection_events: List[Dict],  # [{"detected_time": 11.2}, ...]
    max_detection_window: float = 10.0  # Gi√¢y
) -> float:
    """
    T√≠nh MTTD theo events
    
    Args:
        incident_events: List c√°c incident th·ª±c t·∫ø
        detection_events: List c√°c detection t·ª´ model
        max_detection_window: Window t·ªëi ƒëa ƒë·ªÉ match detection v·ªõi incident
        
    Returns:
        MTTD (gi√¢y)
    """
    detection_times = []
    matched_detections = set()
    
    for incident in incident_events:
        incident_start = incident["start_time"]
        best_detection = None
        best_time_diff = float('inf')
        
        for i, detection in enumerate(detection_events):
            if i in matched_detections:
                continue
            
            detection_time = detection["detected_time"]
            time_diff = detection_time - incident_start
            
            if 0 <= time_diff <= max_detection_window:
                if time_diff < best_time_diff:
                    best_time_diff = time_diff
                    best_detection = i
        
        if best_detection is not None:
            detection_times.append(best_time_diff)
            matched_detections.add(best_detection)
    
    if len(detection_times) == 0:
        return 0.0
    
    return np.mean(detection_times)
```

---

## 4. BI·ªÇU ƒê·ªí B·∫ÆT BU·ªòC

### 4.1. Danh s√°ch Bi·ªÉu ƒë·ªì

1. **PR Curve (Precision-Recall Curve)**
2. **ROC Curve (Receiver Operating Characteristic)**
3. **Confusion Matrix**
4. **FAR vs Recall Curve**
5. **Latency Histogram**
6. **Loss Curves (Training/Validation)**
7. **MTTD Distribution**

### 4.2. Code Template

```python
def generate_all_evaluation_plots(
    y_true: np.ndarray,
    y_pred: np.ndarray,
    y_proba: np.ndarray,
    latencies: List[float],
    mttd_values: List[float],
    save_dir: Path
):
    """
    T·∫°o t·∫•t c·∫£ bi·ªÉu ƒë·ªì ƒë√°nh gi√°
    """
    import matplotlib.pyplot as plt
    from sklearn.metrics import roc_curve, auc, precision_recall_curve
    
    save_dir = Path(save_dir)
    save_dir.mkdir(parents=True, exist_ok=True)
    
    # 1. PR Curve
    precision, recall, pr_thresholds = precision_recall_curve(y_true, y_proba)
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, linewidth=2)
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.grid(True)
    plt.savefig(save_dir / "pr_curve.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    # 2. ROC Curve
    fpr, tpr, roc_thresholds = roc_curve(y_true, y_proba)
    roc_auc = auc(fpr, tpr)
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, linewidth=2, label=f'ROC (AUC = {roc_auc:.3f})')
    plt.plot([0, 1], [0, 1], 'k--', linewidth=1)
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')
    plt.legend()
    plt.grid(True)
    plt.savefig(save_dir / "roc_curve.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    # 3. Confusion Matrix
    from sklearn.metrics import confusion_matrix
    import seaborn as sns
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title('Confusion Matrix')
    plt.savefig(save_dir / "confusion_matrix.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    # 4. FAR vs Recall
    thresholds = np.arange(0.1, 0.95, 0.01)
    recalls = []
    fars = []
    for threshold in thresholds:
        y_pred_thresh = (y_proba >= threshold).astype(int)
        recall = recall_score(y_true, y_pred_thresh, zero_division=0)
        cm = confusion_matrix(y_true, y_pred_thresh)
        if cm.size == 4:
            tn, fp, fn, tp = cm.ravel()
            far = fp / (fp + tn) if (fp + tn) > 0 else 0.0
        else:
            far = 0.0
        recalls.append(recall)
        fars.append(far)
    
    plt.figure(figsize=(8, 6))
    plt.plot(recalls, fars, linewidth=2)
    plt.xlabel('Recall')
    plt.ylabel('False Alarm Rate (FAR)')
    plt.title('FAR vs Recall Curve')
    plt.grid(True)
    plt.savefig(save_dir / "far_vs_recall.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    # 5. Latency Histogram
    plt.figure(figsize=(8, 6))
    plt.hist(latencies, bins=50, edgecolor='black')
    plt.xlabel('Latency (ms)')
    plt.ylabel('Frequency')
    plt.title('Latency Distribution')
    plt.axvline(np.percentile(latencies, 95), color='r', linestyle='--', 
                label=f'p95: {np.percentile(latencies, 95):.2f}ms')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig(save_dir / "latency_histogram.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    # 6. MTTD Distribution
    if mttd_values:
        plt.figure(figsize=(8, 6))
        plt.hist(mttd_values, bins=30, edgecolor='black')
        plt.xlabel('Time to Detection (seconds)')
        plt.ylabel('Frequency')
        plt.title('MTTD Distribution')
        plt.axvline(np.mean(mttd_values), color='r', linestyle='--', 
                    label=f'Mean: {np.mean(mttd_values):.2f}s')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.savefig(save_dir / "mttd_distribution.png", dpi=300, bbox_inches='tight')
        plt.close()
```

---

## 5. CHECKLIST KI·ªÇM TRA SAI L·∫¶M

### 5.1. Data Leakage

- [ ] **Ki·ªÉm tra**: C√≥ incident n√†o xu·∫•t hi·ªán ·ªü c·∫£ train v√† test kh√¥ng?
  - **C√°ch ki·ªÉm tra**: So s√°nh metadata/ID c·ªßa incidents
  - **C√°ch s·ª≠a**: Chia l·∫°i theo incident-level

- [ ] **Ki·ªÉm tra**: C√≥ camera n√†o xu·∫•t hi·ªán ·ªü c·∫£ train v√† test kh√¥ng?
  - **C√°ch ki·ªÉm tra**: Group theo camera_id, ki·ªÉm tra overlap
  - **C√°ch s·ª≠a**: Chia theo camera-level

- [ ] **Ki·ªÉm tra**: Test set c√≥ d·ªØ li·ªáu t·ª´ t∆∞∆°ng lai kh√¥ng?
  - **C√°ch ki·ªÉm tra**: So s√°nh timestamps
  - **C√°ch s·ª≠a**: Chia time-based (train tr∆∞·ªõc, test sau)

### 5.2. Class Imbalance

- [ ] **Ki·ªÉm tra**: T·ªâ l·ªá normal/incident trong train/val/test
  - **C√°ch ki·ªÉm tra**: `np.bincount(y_train)`, `np.bincount(y_test)`
  - **C√°ch s·ª≠a**: Stratified split, class weights, SMOTE

- [ ] **Ki·ªÉm tra**: Model c√≥ bias v·ªÅ class ƒëa s·ªë kh√¥ng?
  - **C√°ch ki·ªÉm tra**: Confusion matrix, xem TP/TN/FP/FN
  - **C√°ch s·ª≠a**: Class weights, focal loss, resampling

### 5.3. Threshold Issues

- [ ] **Ki·ªÉm tra**: Threshold c√≥ ƒë∆∞·ª£c tune tr√™n validation kh√¥ng?
  - **C√°ch ki·ªÉm tra**: Xem code c√≥ `tune_threshold_on_validation()` kh√¥ng
  - **C√°ch s·ª≠a**: Implement threshold tuning

- [ ] **Ki·ªÉm tra**: Threshold c√≥ ph√π h·ª£p v·ªõi m·ª•c ti√™u v·∫≠n h√†nh kh√¥ng?
  - **C√°ch ki·ªÉm tra**: V·∫Ω FAR vs Recall curve, xem c√≥ ƒë·∫°t target kh√¥ng
  - **C√°ch s·ª≠a**: ƒêi·ªÅu ch·ªânh target ho·∫∑c threshold

### 5.4. Label Noise

- [ ] **Ki·ªÉm tra**: C√≥ label sai kh√¥ng?
  - **C√°ch ki·ªÉm tra**: Xem sample FP/FN, ki·ªÉm tra manual
  - **C√°ch s·ª≠a**: Relabel, lo·∫°i b·ªè noisy samples

### 5.5. Train/Val Mismatch

- [ ] **Ki·ªÉm tra**: Distribution c·ªßa train v√† val c√≥ kh√°c nhau kh√¥ng?
  - **C√°ch ki·ªÉm tra**: So s√°nh statistics (mean, std) c·ªßa features
  - **C√°ch s·ª≠a**: Chia l·∫°i data, normalize chung

### 5.6. Overfitting

- [ ] **Ki·ªÉm tra**: Train accuracy >> Val accuracy?
  - **C√°ch ki·ªÉm tra**: So s√°nh metrics train vs val
  - **C√°ch s·ª≠a**: Dropout, regularization, early stopping, th√™m data

### 5.7. Metrics Calculation

- [ ] **Ki·ªÉm tra**: FAR c√≥ ƒë∆∞·ª£c t√≠nh ƒë√∫ng kh√¥ng?
  - **C√°ch ki·ªÉm tra**: `FAR = FP / (FP + TN)`, kh√¥ng ph·∫£i `FP / (FP + TP)`
  - **C√°ch s·ª≠a**: S·ª≠a c√¥ng th·ª©c

- [ ] **Ki·ªÉm tra**: MTTD c√≥ ƒë∆∞·ª£c t√≠nh ƒë√∫ng kh√¥ng?
  - **C√°ch ki·ªÉm tra**: Manual check v·ªõi sample incidents
  - **C√°ch s·ª≠a**: S·ª≠a logic t√≠nh MTTD

### 5.8. Temporal Confirmation

- [ ] **Ki·ªÉm tra**: Temporal confirmation c√≥ gi·∫£m FAR kh√¥ng?
  - **C√°ch ki·ªÉm tra**: So s√°nh FAR tr∆∞·ªõc v√† sau khi apply temporal confirmation
  - **C√°ch s·ª≠a**: Tune parameters (K, window, threshold, cooldown)

---

## üìù T√ìM T·∫ÆT

1. **Chia data**: Theo incident/camera/time, kh√¥ng random
2. **Tune threshold**: Tr√™n validation, theo m·ª•c ti√™u v·∫≠n h√†nh
3. **T√≠nh MTTD**: Theo event ho·∫∑c frame, ƒë√∫ng ƒë·ªãnh nghƒ©a
4. **V·∫Ω bi·ªÉu ƒë·ªì**: PR, ROC, Confusion Matrix, FAR vs Recall, Latency, MTTD
5. **Ki·ªÉm tra**: Data leakage, imbalance, threshold, label noise, overfitting

---

*C·∫≠p nh·∫≠t l·∫ßn cu·ªëi: [Ng√†y hi·ªán t·∫°i]*

