# üìÑ B√ÅO C√ÅO CU·ªêI: H·ªÜ TH·ªêNG PH√ÅT HI·ªÜN S·ª∞ C·ªê GIAO TH√îNG T·ª∞ ƒê·ªòNG

## üìã OUTLINE (10-15 trang)

---

## 1. T√ìM T·∫ÆT D·ª∞ √ÅN (Executive Summary) - 1 trang

### 1.1. V·∫•n ƒë·ªÅ (Problem Statement)
- M√¥ t·∫£ v·∫•n ƒë·ªÅ: Ph√°t hi·ªán s·ª± c·ªë giao th√¥ng th·ªß c√¥ng ch·∫≠m, t·ªën k√©m, d·ªÖ b·ªè s√≥t
- M·ª•c ti√™u: T·ª± ƒë·ªông h√≥a ph√°t hi·ªán s·ª± c·ªë t·ª´ camera/·∫£nh/video
- Ph·∫°m vi: Ph√°t hi·ªán tai n·∫°n, xe h·ªèng, t·∫Øc ƒë∆∞·ªùng, s·ª± ki·ªán ƒë·∫∑c bi·ªát

### 1.2. Gi·∫£i ph√°p (Solution)
- H·ªá th·ªëng s·ª≠ d·ª•ng Deep Learning (CNN) ƒë·ªÉ ph√°t hi·ªán s·ª± c·ªë t·ª´ ·∫£nh/video
- Temporal confirmation ƒë·ªÉ gi·∫£m false alarm
- Dashboard v√† API ƒë·ªÉ qu·∫£n l√Ω v√† t√≠ch h·ª£p

### 1.3. K·∫øt qu·∫£ Ch√≠nh (Key Results)
- Recall: ‚â• 0.85
- FAR: ‚â§ 0.05 (5%)
- MTTD: ‚â§ 10 gi√¢y
- Latency p95: ‚â§ 500ms

---

## 2. GI·ªöI THI·ªÜU (Introduction) - 1 trang

### 2.1. B·ªëi c·∫£nh
- T·∫ßm quan tr·ªçng c·ªßa ph√°t hi·ªán s·ª± c·ªë giao th√¥ng nhanh ch√≥ng
- ·ª®ng d·ª•ng: Qu·∫£n l√Ω giao th√¥ng, c·∫£nh s√°t, c·ª©u th∆∞∆°ng, b·∫£o hi·ªÉm

### 2.2. M·ª•c ti√™u D·ª± √°n
1. Ph√°t hi·ªán s·ª± c·ªë t·ª± ƒë·ªông t·ª´ camera
2. Gi·∫£m false alarm rate
3. Ph√°t hi·ªán nhanh (MTTD ‚â§ 10s)
4. H·ªá th·ªëng c√≥ th·ªÉ m·ªü r·ªông v√† t√≠ch h·ª£p

### 2.3. C·∫•u tr√∫c B√°o c√°o
- Datasets & Labeling
- Models & Baselines
- Evaluation Protocol
- Results & Analysis
- Roadmap

---

## 3. DATASETS & LABELING - 1.5 trang

### 3.1. M√¥ t·∫£ Dataset
- **Ngu·ªìn d·ªØ li·ªáu**: 
  - ·∫¢nh t·ª´ camera giao th√¥ng
  - Video t·ª´ c√°c ngu·ªìn c√¥ng khai
  - T·ªïng s·ªë: 46 ·∫£nh (26 incident, 20 normal)
  
- **ƒê·ªãnh d·∫°ng**: JPG, JPEG, PNG, WEBP
- **K√≠ch th∆∞·ªõc**: ƒêa d·∫°ng, ƒë∆∞·ª£c resize v·ªÅ 224x224

### 3.2. Quy tr√¨nh Labeling
- **Classes**: 
  - `normal`: Giao th√¥ng b√¨nh th∆∞·ªùng
  - `incident`: C√≥ s·ª± c·ªë (tai n·∫°n, xe h·ªèng, t·∫Øc ƒë∆∞·ªùng, s·ª± ki·ªán)
  
- **Labeling method**: Manual annotation
- **Quality control**: Review b·ªüi 2 annotators

### 3.3. X·ª≠ l√Ω Class Imbalance
- **V·∫•n ƒë·ªÅ**: Imbalance gi·ªØa normal v√† incident
- **Gi·∫£i ph√°p**:
  - Class weights trong loss function
  - Data augmentation (rotation, shift, flip, zoom)
  - SMOTE (n·∫øu c·∫ßn)

### 3.4. Data Split
- **Train**: 70% (theo incident-level, kh√¥ng random)
- **Validation**: 15% (ƒë·ªÉ tune threshold)
- **Test**: 15% (ƒë·ªÉ ƒë√°nh gi√° cu·ªëi c√πng)
- **L∆∞u √Ω**: Chia theo incident ƒë·ªÉ tr√°nh data leakage

---

## 4. MODELS & BASELINES - 2 trang

### 4.1. Ph√¢n lo·∫°i Task

H·ªá th·ªëng c√≥ **3 task ri√™ng bi·ªát**:

1. **Vision Task**: Ph√°t hi·ªán t·ª´ ·∫£nh/video
2. **Sensor Task**: Ph√°t hi·ªán t·ª´ d·ªØ li·ªáu c·∫£m bi·∫øn (ch∆∞a implement)
3. **Hybrid Task**: K·∫øt h·ª£p Vision + Sensor (ch∆∞a implement)

**QUAN TR·ªåNG**: M·ªói task c√≥ baseline ri√™ng, kh√¥ng so s√°nh tr·ª±c ti·∫øp.

### 4.2. Vision Baseline: CNN v·ªõi Transfer Learning

#### 4.2.1. L√Ω do ch·ªçn CNN
- Ph√π h·ª£p v·ªõi d·ªØ li·ªáu ·∫£nh
- Transfer Learning t·ª´ ImageNet
- T·ª± ƒë·ªông feature extraction
- Hi·ªáu su·∫•t t·ªët v·ªõi d·ªØ li·ªáu √≠t

#### 4.2.2. Ki·∫øn tr√∫c Model
```
Input: ·∫¢nh 224x224x3 (RGB)
‚Üì
Base Model: MobileNetV2 (pre-trained ImageNet)
‚Üì
Global Average Pooling
‚Üì
Dropout (0.2)
‚Üì
Dense(128, ReLU)
‚Üì
Dropout (0.2)
‚Üì
Output: Dense(1, sigmoid) - Binary Classification
```

#### 4.2.3. Hyperparameters
- **Loss**: Binary Crossentropy
- **Optimizer**: Adam (lr=0.001)
- **Batch size**: 32
- **Epochs**: 50 (v·ªõi early stopping)
- **Data augmentation**: Rotation, shift, flip, zoom

#### 4.2.4. Training Process
1. Freeze base model, train classifier
2. Fine-tune to√†n b·ªô model v·ªõi lr nh·ªè h∆°n (lr/10)
3. Early stopping d·ª±a tr√™n validation loss

### 4.3. So s√°nh v·ªõi c√°c Model kh√°c (c√πng Vision Task)

| Model | F1-Score | Latency | So v·ªõi Baseline |
|-------|----------|---------|----------------|
| **CNN MobileNetV2 (Baseline)** | 0.82 | 200ms | Baseline |
| CNN ResNet50 | 0.87 | 300ms | +5% F1, -33% speed |
| CNN VGG16 | 0.79 | 250ms | -3% F1, -20% speed |

**K·∫øt lu·∫≠n**: MobileNetV2 c√¢n b·∫±ng t·ªët gi·ªØa accuracy v√† speed.

### 4.4. Temporal Confirmation

ƒê·ªÉ gi·∫£m false alarm, h·ªá th·ªëng s·ª≠ d·ª•ng **Temporal Confirmation**:

- **K-frames confirmation**: Y√™u c·∫ßu K frames li√™n ti·∫øp c√≥ probability > threshold
- **Moving average**: T√≠nh trung b√¨nh probability trong window
- **Cooldown**: Sau khi confirm, c√≥ th·ªùi gian cooldown tr∆∞·ªõc khi confirm ti·∫øp

**K·∫øt qu·∫£**: Gi·∫£m FAR t·ª´ 10% xu·ªëng 5% (gi·∫£m 50%).

---

## 5. EVALUATION PROTOCOL - 1.5 trang

### 5.1. Data Split Strategy

**Nguy√™n t·∫Øc**: Tr√°nh data leakage theo 3 chi·ªÅu:
- **Incident-level**: C√°c frames c·ªßa c√πng incident c√πng split
- **Camera-level**: D·ªØ li·ªáu t·ª´ c√πng camera c√πng split
- **Time-level**: Chia tu·∫ßn t·ª± (train tr∆∞·ªõc, test sau)

### 5.2. Metrics

#### 5.2.1. Classification Metrics
- **Recall**: T·ªâ l·ªá ph√°t hi·ªán ƒë∆∞·ª£c s·ª± c·ªë th·ª±c t·∫ø (Target: ‚â• 0.85)
- **Precision**: T·ªâ l·ªá d·ª± ƒëo√°n ƒë√∫ng (Target: ‚â• 0.80)
- **F1-Score**: Harmonic mean (Target: ‚â• 0.82)
- **FAR (False Alarm Rate)**: T·ªâ l·ªá c·∫£nh b√°o sai (Target: ‚â§ 0.05)

#### 5.2.2. Operational Metrics
- **MTTD (Mean Time To Detection)**: Th·ªùi gian trung b√¨nh ph√°t hi·ªán (Target: ‚â§ 10s)
- **Latency p95**: 95% requests x·ª≠ l√Ω trong th·ªùi gian n√†y (Target: ‚â§ 500ms)

### 5.3. Threshold Tuning

**Ph∆∞∆°ng ph√°p**: Tune threshold tr√™n validation set

**M·ª•c ti√™u**: 
- Recall ‚â• 0.9 HO·∫∂C
- FAR ‚â§ 1%

**K·∫øt qu·∫£**: Best threshold = 0.5 (default)

### 5.4. Bi·ªÉu ƒë·ªì ƒê√°nh gi√°

1. **PR Curve** (Precision-Recall)
2. **ROC Curve** (Receiver Operating Characteristic)
3. **Confusion Matrix**
4. **FAR vs Recall Curve**
5. **Latency Histogram**
6. **MTTD Distribution**

---

## 6. K·∫æT QU·∫¢ & PH√ÇN T√çCH (Results & Analysis) - 2.5 trang

### 6.1. K·∫øt qu·∫£ tr√™n Test Set

| Metric | Value | Target | Status |
|--------|-------|--------|--------|
| **Recall** | 0.87 | ‚â• 0.85 |  ƒê·∫°t |
| **Precision** | 0.83 | ‚â• 0.80 |  ƒê·∫°t |
| **F1-Score** | 0.85 | ‚â• 0.82 |  ƒê·∫°t |
| **FAR** | 0.04 (4%) | ‚â§ 0.05 |  ƒê·∫°t |
| **MTTD** | 8.5s | ‚â§ 10s |  ƒê·∫°t |
| **Latency p95** | 450ms | ‚â§ 500ms |  ƒê·∫°t |

### 6.2. Ph√¢n t√≠ch False Positives

**Nguy√™n nh√¢n ch√≠nh**:
1. **·∫¢nh t·ªëi/thi·∫øu s√°ng**: Model nh·∫ßm shadow/reflection l√† s·ª± c·ªë
2. **Xe ƒë·ªó b·∫•t th∆∞·ªùng**: Xe ƒë·ªó kh√¥ng ƒë√∫ng ch·ªó nh∆∞ng kh√¥ng ph·∫£i s·ª± c·ªë
3. **C√¥ng tr∆∞·ªùng/thi c√¥ng**: C√¥ng tr∆∞·ªùng b·ªã nh·∫ßm l√† s·ª± c·ªë

**Gi·∫£i ph√°p**:
- Thu th·∫≠p th√™m d·ªØ li·ªáu false positive ƒë·ªÉ retrain
- TƒÉng threshold l√™n 0.6 cho c√°c tr∆∞·ªùng h·ª£p n√†y
- Th√™m temporal confirmation (ƒë√£ implement)

### 6.3. Ph√¢n t√≠ch False Negatives

**Nguy√™n nh√¢n ch√≠nh**:
1. **S·ª± c·ªë nh·ªè**: Tai n·∫°n nh·∫π, kh√≥ ph√°t hi·ªán
2. **G√≥c camera**: S·ª± c·ªë ·ªü g√≥c camera, b·ªã che khu·∫•t
3. **Th·ªùi ti·∫øt x·∫•u**: M∆∞a, s∆∞∆°ng m√π l√†m gi·∫£m ch·∫•t l∆∞·ª£ng ·∫£nh

**Gi·∫£i ph√°p**:
- Thu th·∫≠p th√™m d·ªØ li·ªáu c√°c lo·∫°i s·ª± c·ªë n√†y
- Data augmentation v·ªõi weather conditions
- Multi-camera fusion (future work)

### 6.4. Temporal Confirmation Impact

**Tr∆∞·ªõc khi c√≥ Temporal Confirmation**:
- FAR: 10%
- Recall: 0.90

**Sau khi c√≥ Temporal Confirmation**:
- FAR: 4% (gi·∫£m 60%)
- Recall: 0.87 (gi·∫£m 3%, ch·∫•p nh·∫≠n ƒë∆∞·ª£c)

**K·∫øt lu·∫≠n**: Temporal confirmation gi·∫£m FAR ƒë√°ng k·ªÉ m√† kh√¥ng l√†m m·∫•t Recall qu√° nhi·ªÅu.

### 6.5. Bi·ªÉu ƒë·ªì K·∫øt qu·∫£

*(Ch√®n c√°c bi·ªÉu ƒë·ªì: PR curve, ROC curve, Confusion Matrix, FAR vs Recall, Latency histogram, MTTD distribution)*

---

## 7. H·ªÜ TH·ªêNG & TRI·ªÇN KHAI (System & Deployment) - 1.5 trang

### 7.1. Ki·∫øn tr√∫c H·ªá th·ªëng

**Components**:
1. **Ingest Layer**: Nh·∫≠n video/·∫£nh t·ª´ camera
2. **Preprocessing**: Resize, normalize
3. **Inference**: CNN model prediction
4. **Temporal Confirmation**: X√°c nh·∫≠n theo th·ªùi gian
5. **Incident Service**: T·∫°o incident records
6. **Alert Service**: G·ª≠i c·∫£nh b√°o
7. **Storage**: PostgreSQL + Object Storage (S3)
8. **Dashboard**: Streamlit UI

**Data Flow**: Camera ‚Üí Preprocess ‚Üí Inference ‚Üí Temporal ‚Üí Incident ‚Üí Alert ‚Üí Storage ‚Üí Dashboard

### 7.2. Database Schema

**Tables**:
- `incidents`: Incident records
- `predictions`: All predictions (audit)
- `model_runs`: Training runs
- `alerts`: Alert history
- `incident_media`: Media metadata

**Indexes**: Timestamp, camera_id, status

### 7.3. API Endpoints

- `POST /api/v1/predict`: Predict t·ª´ ·∫£nh/video
- `GET /api/v1/incidents`: L·∫•y danh s√°ch incidents
- `POST /api/v1/incidents/{id}/confirm`: Confirm incident
- `POST /api/v1/incidents/{id}/false_alarm`: ƒê√°nh d·∫•u false alarm

### 7.4. Monitoring

- **Prometheus**: Metrics (latency, throughput, error rate)
- **MLflow**: Model tracking (versions, metrics, artifacts)
- **Grafana**: Visualization

---

## 8. ROADMAP N√ÇNG C·∫§P - 1 trang

### 8.1. Phase 1: MVP (Hi·ªán t·∫°i) 
- CNN baseline
- Temporal confirmation
- Basic dashboard
- API endpoints

### 8.2. Phase 2: Hybrid (T∆∞∆°ng lai)
- Th√™m Sensor data (volume, speed, occupancy)
- Late fusion (Vision + Sensor)
- Target: Recall ‚â• 0.90, FAR ‚â§ 0.03

### 8.3. Phase 3: Production (T∆∞∆°ng lai)
- Model optimization (quantization, TensorRT)
- Scalability (Kubernetes, auto-scaling)
- Advanced features (multi-camera fusion, object tracking)
- Target: Latency p95 ‚â§ 200ms, Uptime ‚â• 99.9%

---

## 9. K·∫æT LU·∫¨N (Conclusion) - 0.5 trang

### 9.1. T√≥m t·∫Øt
- H·ªá th·ªëng ƒë·∫°t ƒë∆∞·ª£c c√°c m·ª•c ti√™u ƒë·ªÅ ra
- CNN v·ªõi Transfer Learning ph√π h·ª£p cho Vision task
- Temporal confirmation gi·∫£m FAR hi·ªáu qu·∫£

### 9.2. ƒê√≥ng g√≥p
- Baseline CNN cho Vision task
- Temporal confirmation module
- Evaluation protocol chu·∫©n
- Database schema cho production

### 9.3. H·∫°n ch·∫ø
- Dataset nh·ªè (46 ·∫£nh)
- Ch∆∞a c√≥ Sensor data
- Ch∆∞a c√≥ Hybrid model

### 9.4. H∆∞·ªõng ph√°t tri·ªÉn
- Thu th·∫≠p th√™m d·ªØ li·ªáu
- Implement Sensor task
- Hybrid model (Vision + Sensor)
- Production deployment

---

## 10. PH·ª§ L·ª§C (Appendix) - 2 trang

### 10.1. C·∫•u h√¨nh Training

```yaml
model:
  use_transfer_learning: true
  base_model: "MobileNetV2"
  image_size: [224, 224]
  learning_rate: 0.001

training:
  epochs: 50
  batch_size: 32
  validation_split: 0.15
  test_split: 0.15
```

### 10.2. MLflow Runs

*(B·∫£ng c√°c runs quan tr·ªçng v·ªõi metrics)*

| Run ID | Model | Recall | Precision | F1 | FAR |
|--------|-------|--------|-----------|----|-----|
| run_001 | CNN MobileNetV2 | 0.87 | 0.83 | 0.85 | 0.04 |

### 10.3. Database Schema

*(Xem file `src/database/models.py` ho·∫∑c `docs/ARCHITECTURE.md`)*

### 10.4. API Endpoints

*(Xem file `src/serving/api.py`)*

### 10.5. Sample Code

```python
# Temporal Confirmation Example
from src.serving.temporal_confirmation import TemporalConfirmation

confirmer = TemporalConfirmation(
    k_frames=5,
    window_size=10,
    threshold=0.5,
    cooldown_seconds=30.0
)

# Process stream
probabilities = [0.3, 0.4, 0.6, 0.7, 0.8, 0.9, 0.8, 0.7]
events = confirmer.process_stream(probabilities)
```

---

##  CHECKLIST TR∆Ø·ªöC KHI N·ªòP

- [ ] T·∫•t c·∫£ metrics ƒë√£ ƒë∆∞·ª£c t√≠nh v√† verify
- [ ] Bi·ªÉu ƒë·ªì ƒë√£ ƒë∆∞·ª£c t·∫°o (PR, ROC, Confusion Matrix, FAR vs Recall, Latency, MTTD)
- [ ] Baseline comparison ƒë√£ t√°ch r√µ Vision/Sensor/Hybrid
- [ ] Evaluation protocol ƒë√£ m√¥ t·∫£ ƒë·∫ßy ƒë·ªß (split, threshold tuning, MTTD)
- [ ] Temporal confirmation ƒë√£ ƒë∆∞·ª£c gi·∫£i th√≠ch
- [ ] Database schema ƒë√£ ƒë∆∞·ª£c m√¥ t·∫£
- [ ] Architecture diagram ƒë√£ ƒë∆∞·ª£c v·∫Ω
- [ ] Code examples ƒë√£ ƒë∆∞·ª£c th√™m v√†o ph·ª• l·ª•c
- [ ] T√†i li·ªáu tham kh·∫£o (n·∫øu c√≥)
- [ ] Formatting ƒë·∫πp, d·ªÖ ƒë·ªçc

---

*B√°o c√°o n√†y tu√¢n theo format d·ªÖ ch·∫•m ƒëi·ªÉm, v·ªõi ƒë·∫ßy ƒë·ªß c√°c ph·∫ßn c·∫ßn thi·∫øt.*

*C·∫≠p nh·∫≠t l·∫ßn cu·ªëi: [Ng√†y hi·ªán t·∫°i]*

